{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Learning LangGraph with BigQuery Agent\n",
    "\n",
    "This notebook provides a hands-on introduction to LangGraph by building a BigQuery agent that queries data and creates visualisations.\n",
    "\n",
    "## What You'll Learn\n",
    "\n",
    "1. **LangGraph Fundamentals**: StateGraph, nodes, edges, and state management\n",
    "2. **Tool Integration**: Building and using tools for agents\n",
    "3. **Agent Orchestration**: Creating multi-step workflows\n",
    "4. **BigQuery Integration**: Querying and analysing data\n",
    "5. **Data Visualisation**: Automatically selecting and creating appropriate visualisations\n",
    "\n",
    "## Architecture Overview\n",
    "\n",
    "Our agent will follow this workflow:\n",
    "```\n",
    "User Query → Query Planner → BQ Executor → Data Analyser → Visualisation Generator → Response\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 1: LangGraph Basics\n",
    "\n",
    "Let's start by understanding the core concepts of LangGraph."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dependencies imported successfully\n",
      "Project: knowsee-platform-development\n",
      "Location: europe-west2\n"
     ]
    }
   ],
   "source": [
    "# Import dependencies\n",
    "import os\n",
    "import operator\n",
    "from typing import Annotated, TypedDict, Sequence\n",
    "from google.cloud import bigquery\n",
    "from langchain_google_vertexai import ChatVertexAI\n",
    "from langgraph.graph import StateGraph, END\n",
    "from langgraph.prebuilt import ToolNode\n",
    "from langchain_core.messages import BaseMessage, HumanMessage, AIMessage, ToolMessage\n",
    "from langchain_core.tools import tool\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import plotly.express as px\n",
    "import plotly.graph_objects as go\n",
    "\n",
    "# Set up plotting style\n",
    "sns.set_style('whitegrid')\n",
    "plt.rcParams['figure.figsize'] = (12, 6)\n",
    "\n",
    "print(\"Dependencies imported successfully\")\n",
    "print(f\"Project: {os.environ.get('GOOGLE_CLOUD_PROJECT', 'knowsee-platform-development')}\")\n",
    "print(f\"Location: {os.environ.get('GOOGLE_CLOUD_LOCATION', 'europe-west2')}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Understanding State in LangGraph\n",
    "\n",
    "LangGraph uses a **state graph** where each node can read and modify shared state. The state is a typed dictionary that flows through the graph."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "State definition complete\n"
     ]
    }
   ],
   "source": [
    "# Simple example: A state that tracks messages\n",
    "class SimpleAgentState(TypedDict):\n",
    "    messages: Annotated[Sequence[BaseMessage], operator.add]\n",
    "    \n",
    "# The Annotated[Sequence[BaseMessage], operator.add] means:\n",
    "# - It's a sequence of messages\n",
    "# - When updating, use operator.add to append (not replace)\n",
    "\n",
    "print(\"State definition complete\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "__main__.SimpleAgentState"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "SimpleAgentState"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Building Your First Graph\n",
    "\n",
    "Let's create a simple graph with two nodes: one that greets and one that responds."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Simple graph created!\n"
     ]
    }
   ],
   "source": [
    "# Define node functions\n",
    "def greeting_node(state: SimpleAgentState) -> SimpleAgentState:\n",
    "    \"\"\"First node: adds a greeting message\"\"\"\n",
    "    return {\n",
    "        \"messages\": [AIMessage(content=\"Hello! I'm your LangGraph agent.\")]\n",
    "    }\n",
    "\n",
    "def response_node(state: SimpleAgentState) -> SimpleAgentState:\n",
    "    \"\"\"Second node: adds a response based on user input\"\"\"\n",
    "    user_message = state[\"messages\"][-1].content if state[\"messages\"] else \"nothing\"\n",
    "    return {\n",
    "        \"messages\": [AIMessage(content=f\"You said: {user_message}\")]\n",
    "    }\n",
    "\n",
    "# Create the graph\n",
    "simple_graph = StateGraph(SimpleAgentState)\n",
    "\n",
    "# Add nodes\n",
    "simple_graph.add_node(\"greet\", greeting_node)\n",
    "simple_graph.add_node(\"respond\", response_node)\n",
    "\n",
    "# Add edges (define the flow)\n",
    "simple_graph.set_entry_point(\"greet\")\n",
    "simple_graph.add_edge(\"greet\", \"respond\")\n",
    "simple_graph.add_edge(\"respond\", END)\n",
    "\n",
    "# Compile the graph\n",
    "simple_app = simple_graph.compile()\n",
    "\n",
    "print(\"Simple graph created!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<langgraph.graph.state.CompiledStateGraph object at 0x16b7b42d0>"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "simple_app"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Messages in final state:\n",
      "  HumanMessage: I want to learn LangGraph\n",
      "  AIMessage: Hello! I'm your LangGraph agent.\n",
      "  AIMessage: You said: Hello! I'm your LangGraph agent.\n"
     ]
    }
   ],
   "source": [
    "# Test the simple graph\n",
    "result = simple_app.invoke({\n",
    "    \"messages\": [HumanMessage(content=\"I want to learn LangGraph\")]\n",
    "})\n",
    "\n",
    "print(\"Messages in final state:\")\n",
    "for msg in result[\"messages\"]:\n",
    "    print(f\"  {msg.__class__.__name__}: {msg.content}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 2: Setting Up BigQuery Connection\n",
    "\n",
    "Before building our agent, let's connect to BigQuery and explore the public datasets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BigQuery client initialised for project: knowsee-platform-development\n"
     ]
    }
   ],
   "source": [
    "# Set up BigQuery client\n",
    "project_id = os.environ.get('GOOGLE_CLOUD_PROJECT', 'knowsee-platform-development')\n",
    "\n",
    "bq_client = bigquery.Client(project=project_id)\n",
    "print(f\"BigQuery client initialised for project: {project_id}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/homebrew/Caskroom/miniconda/base/envs/platform/lib/python3.14/site-packages/google/cloud/bigquery/table.py:1994: UserWarning: BigQuery Storage module not found, fetch data with the REST endpoint instead.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Connection successful! Top 10 names since 2010:\n",
      "       name  total_births\n",
      "0      Emma        225940\n",
      "1      Noah        221548\n",
      "2    Olivia        219730\n",
      "3      Liam        213851\n",
      "4    Sophia        206500\n",
      "5  Isabella        193709\n",
      "6   William        184474\n",
      "7       Ava        181625\n",
      "8     Jacob        180680\n",
      "9     Mason        177175\n"
     ]
    }
   ],
   "source": [
    "# Test query on a public dataset\n",
    "test_query = \"\"\"\n",
    "SELECT \n",
    "  name, \n",
    "  SUM(number) as total_births\n",
    "FROM `bigquery-public-data.usa_names.usa_1910_current`\n",
    "WHERE year >= 2010\n",
    "GROUP BY name\n",
    "ORDER BY total_births DESC\n",
    "LIMIT 10\n",
    "\"\"\"\n",
    "\n",
    "try:\n",
    "    test_df = bq_client.query(test_query).to_dataframe()\n",
    "    print(\"Connection successful! Top 10 names since 2010:\")\n",
    "    print(test_df)\n",
    "except Exception as e:\n",
    "    print(f\"Error: {e}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 3: Building the BigQuery Agent\n",
    "\n",
    "Now let's build a proper agent with tools and LLM integration."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define the Agent State\n",
    "\n",
    "Our agent needs to track:\n",
    "- Messages (conversation history)\n",
    "- Query data (results from BQ)\n",
    "- Analysis insights\n",
    "- Visualisation recommendations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "class BQAgentState(TypedDict):\n",
    "    messages: Annotated[Sequence[BaseMessage], operator.add]\n",
    "    query_result: pd.DataFrame\n",
    "    analysis: str\n",
    "    visualisation_type: str\n",
    "    user_query: str"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create Tools for the Agent\n",
    "\n",
    "Tools are functions that the LLM can call. We'll create:\n",
    "1. A tool to execute BigQuery queries\n",
    "2. A tool to analyse data\n",
    "3. A tool to generate visualisations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tools defined successfully\n"
     ]
    }
   ],
   "source": [
    "@tool\n",
    "def execute_bigquery(sql_query: str) -> str:\n",
    "    \"\"\"Execute a BigQuery SQL query and return results as a JSON string.\n",
    "    \n",
    "    Args:\n",
    "        sql_query: The SQL query to execute\n",
    "        \n",
    "    Returns:\n",
    "        JSON string containing query results\n",
    "    \"\"\"\n",
    "    print(\"\\n\" + \"=\"*80)\n",
    "    print(\"EXECUTING SQL QUERY:\")\n",
    "    print(\"-\"*80)\n",
    "    print(sql_query)\n",
    "    print(\"=\"*80 + \"\\n\")\n",
    "    \n",
    "    try:\n",
    "        query_job = bq_client.query(sql_query)\n",
    "        df = query_job.to_dataframe()\n",
    "        \n",
    "        # Store in a way that can be retrieved later\n",
    "        # For now, return summary info\n",
    "        result_info = {\n",
    "            \"success\": True,\n",
    "            \"row_count\": len(df),\n",
    "            \"columns\": df.columns.tolist(),\n",
    "            \"sample_data\": df.head(3).to_dict('records'),\n",
    "            \"dtypes\": df.dtypes.astype(str).to_dict()\n",
    "        }\n",
    "        \n",
    "        print(f\"✓ Query succeeded: {len(df)} rows returned\\n\")\n",
    "        \n",
    "        return str(result_info)\n",
    "    except Exception as e:\n",
    "        error_msg = f\"Error executing query: {str(e)}\"\n",
    "        print(f\"✗ {error_msg}\\n\")\n",
    "        return error_msg\n",
    "\n",
    "@tool\n",
    "def list_available_datasets() -> str:\n",
    "    \"\"\"List some available public BigQuery datasets that can be queried.\n",
    "    \n",
    "    Returns:\n",
    "        String describing available datasets\n",
    "    \"\"\"\n",
    "    datasets = \"\"\"\n",
    "    Available public BigQuery datasets:\n",
    "    \n",
    "    1. bigquery-public-data.usa_names.usa_1910_current\n",
    "       - US baby names from 1910 to present\n",
    "       - Columns: state, gender, year, name, number\n",
    "    \n",
    "    2. bigquery-public-data.google_analytics_sample.ga_sessions_*\n",
    "       - Google Analytics session data\n",
    "       - Date range: 20160801 - 20170801\n",
    "    \n",
    "    3. bigquery-public-data.chicago_crime.crime\n",
    "       - Chicago crime data\n",
    "       - Columns: date, primary_type, description, location_description, arrest, etc.\n",
    "    \n",
    "    4. bigquery-public-data.samples.shakespeare\n",
    "       - Shakespeare's works\n",
    "       - Columns: word, word_count, corpus, corpus_date\n",
    "    \"\"\"\n",
    "    return datasets\n",
    "\n",
    "print(\"Tools defined successfully\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Initialise the LLM with Tools"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LLM initialised with tools via Vertex AI\n",
      "Model: gemini-2.5-flash\n",
      "Project: knowsee-platform-development\n",
      "Location: europe-west2\n"
     ]
    }
   ],
   "source": [
    "# Initialise Gemini via Vertex AI\n",
    "llm = ChatVertexAI(\n",
    "    model=\"gemini-2.5-flash\",\n",
    "    temperature=0,\n",
    "    project=os.environ.get('GOOGLE_CLOUD_PROJECT', 'knowsee-platform-development'),\n",
    "    location=os.environ.get('GOOGLE_CLOUD_LOCATION', 'europe-west2'),\n",
    ")\n",
    "\n",
    "# Bind tools to the LLM\n",
    "tools = [execute_bigquery, list_available_datasets]\n",
    "llm_with_tools = llm.bind_tools(tools)\n",
    "\n",
    "print(\"LLM initialised with tools via Vertex AI\")\n",
    "print(f\"Model: gemini-2.5-flash\")\n",
    "print(f\"Project: {llm.project}\")\n",
    "print(f\"Location: {llm.location}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define Agent Nodes\n",
    "\n",
    "Each node represents a step in our agent's workflow."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RunnableBinding(bound=ChatVertexAI(profile={'max_input_tokens': 1048576, 'max_output_tokens': 65536, 'image_inputs': True, 'audio_inputs': True, 'pdf_inputs': True, 'video_inputs': True, 'image_outputs': False, 'audio_outputs': False, 'video_outputs': False, 'reasoning_output': True, 'tool_calling': True, 'image_url_inputs': True, 'image_tool_message': True, 'tool_choice': True, 'structured_output': True}, project='knowsee-platform-development', location='europe-west2', model_name='gemini-2.5-flash', full_model_name='projects/knowsee-platform-development/locations/europe-west2/publishers/google/models/gemini-2.5-flash', client_options=ClientOptions: {'api_endpoint': 'europe-west2-aiplatform.googleapis.com', 'client_cert_source': None, 'client_encrypted_cert_source': None, 'quota_project_id': None, 'credentials_file': None, 'scopes': None, 'api_key': None, 'api_audience': None, 'universe_domain': None}, default_metadata=(), temperature=0.0, model_kwargs={}), kwargs={'tools': [{'type': 'function', 'function': {'name': 'execute_bigquery', 'description': 'Execute a BigQuery SQL query and return results as a JSON string.\\n\\nArgs:\\n    sql_query: The SQL query to execute\\n\\nReturns:\\n    JSON string containing query results', 'parameters': {'properties': {'sql_query': {'type': 'string'}}, 'required': ['sql_query'], 'type': 'object'}}}, {'type': 'function', 'function': {'name': 'list_available_datasets', 'description': 'List some available public BigQuery datasets that can be queried.\\n\\nReturns:\\n    String describing available datasets', 'parameters': {'properties': {}, 'type': 'object'}}}]}, config={}, config_factories=[])"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "llm_with_tools"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# What This Function Does\n",
    "\n",
    "#   def should_continue(state: BQAgentState) -> str:\n",
    "#       \"\"\"Decide whether to continue with tools or end.\"\"\"\n",
    "#       messages = state[\"messages\"]\n",
    "#       last_message = messages[-1]\n",
    "\n",
    "#       # If there are tool calls, continue to tools\n",
    "#       if hasattr(last_message, 'tool_calls') and last_message.tool_calls:\n",
    "#           return \"tools\"\n",
    "#       # Otherwise, end\n",
    "#       return \"end\"\n",
    "\n",
    "#   This function inspects the last message and returns either:\n",
    "#   - \"tools\" → Go execute tools\n",
    "#   - \"end\" → Stop, we're done\n",
    "\n",
    "#   Breaking Down the Condition\n",
    "\n",
    "#   Part 1: hasattr(last_message, 'tool_calls')\n",
    "\n",
    "#   Safety check: Does this message object have a tool_calls attribute?\n",
    "\n",
    "#   - HumanMessage → No tool_calls attribute\n",
    "#   - ToolMessage → No tool_calls attribute\n",
    "#   - AIMessage → Has tool_calls attribute (might be None or empty)\n",
    "\n",
    "#   This prevents crashes if you accidentally check a message type that doesn't have this attribute.\n",
    "\n",
    "#   Part 2: and last_message.tool_calls\n",
    "\n",
    "#   Truthiness check: Is tool_calls not empty?\n",
    "\n",
    "#   # These are \"falsy\" (would return \"end\"):\n",
    "#   tool_calls = None        # LLM didn't want to call tools\n",
    "#   tool_calls = []          # Empty list (no tools to call)\n",
    "\n",
    "#   # These are \"truthy\" (would return \"tools\"):\n",
    "#   tool_calls = [{'name': 'execute_bigquery', 'args': {...}}]\n",
    "\n",
    "#   How This Creates the Loop\n",
    "\n",
    "#   Remember your graph structure:\n",
    "\n",
    "#   agent → should_continue → {tools: \"tools\", end: END}\n",
    "#             ↑                    ↓\n",
    "#             └────────────────────┘\n",
    "\n",
    "#   Scenario 1: LLM wants to use a tool\n",
    "#   # agent_node returns:\n",
    "#   AIMessage(\n",
    "#       content=\"\",\n",
    "#       tool_calls=[{'name': 'execute_bigquery', 'args': {...}}]\n",
    "#   )\n",
    "\n",
    "#   # should_continue checks:\n",
    "#   hasattr(msg, 'tool_calls')  → True\n",
    "#   msg.tool_calls              → [{'name': ...}]  (truthy!)\n",
    "\n",
    "#   # Returns: \"tools\"\n",
    "#   # Flow: agent → should_continue → tools → agent (loops back!)\n",
    "\n",
    "#   Scenario 2: LLM provides final answer\n",
    "#   # agent_node returns:\n",
    "#   AIMessage(\n",
    "#       content=\"The top 5 names are Emma, Olivia...\",\n",
    "#       tool_calls=None  # or []\n",
    "#   )\n",
    "\n",
    "#   # should_continue checks:\n",
    "#   hasattr(msg, 'tool_calls')  → True\n",
    "#   msg.tool_calls              → None (falsy!)\n",
    "\n",
    "#   # Returns: \"end\"\n",
    "#   # Flow: agent → should_continue → END (stops!)\n",
    "\n",
    "#   Visual Example\n",
    "\n",
    "#   Let me show you what happens with a real query:\n",
    "\n",
    "#   User: \"Get top 5 names in 2020\"\n",
    "#       ↓\n",
    "#   [agent_node]\n",
    "#       ↓\n",
    "#   AIMessage(tool_calls=[{execute_bigquery}])  ← LLM: \"I need data!\"\n",
    "#       ↓\n",
    "#   [should_continue]\n",
    "#       ↓\n",
    "#   Check: tool_calls exists? YES → return \"tools\"\n",
    "#       ↓\n",
    "#   [ToolNode] executes SQL\n",
    "#       ↓\n",
    "#   ToolMessage(result=\"{'success': True, ...}\")\n",
    "#       ↓\n",
    "#   [agent_node] ← Back to agent with results!\n",
    "#       ↓\n",
    "#   AIMessage(content=\"The top 5 names are...\", tool_calls=None)  ← LLM: \"I have the answer!\"\n",
    "#       ↓\n",
    "#   [should_continue]\n",
    "#       ↓\n",
    "#   Check: tool_calls exists? None → return \"end\"\n",
    "#       ↓\n",
    "#   [END] ← Done!\n",
    "\n",
    "#   Why Both Checks?\n",
    "\n",
    "#   Why not just if last_message.tool_calls:?\n",
    "\n",
    "#   Because this would crash if last_message doesn't have the attribute:\n",
    "\n",
    "#   # Without hasattr:\n",
    "#   human_msg = HumanMessage(content=\"Hello\")\n",
    "#   human_msg.tool_calls  # ← AttributeError: HumanMessage has no attribute 'tool_calls'\n",
    "\n",
    "#   # With hasattr:\n",
    "#   if hasattr(human_msg, 'tool_calls') and human_msg.tool_calls:\n",
    "#       # Never gets here, safely returns False\n",
    "\n",
    "#   ★ Insight ─────────────────────────────────────\n",
    "#   Conditional Edges Are Routing Logic: In LangGraph, conditional edges are functions that return strings. Those strings map to\n",
    "#    node names in your graph definition:\n",
    "\n",
    "#   workflow.add_conditional_edges(\n",
    "#       \"agent\",           # From this node\n",
    "#       should_continue,   # Call this function\n",
    "#       {\n",
    "#           \"tools\": \"tools\",  # If returns \"tools\", go to \"tools\" node\n",
    "#           \"end\": END         # If returns \"end\", stop\n",
    "#       }\n",
    "#   )\n",
    "\n",
    "#   This is how you implement dynamic control flow in agents:\n",
    "#   - Continue looping (tools → agent → tools)\n",
    "#   - Exit when done (agent → END)\n",
    "#   - Branch to different paths (could have \"error\", \"human_review\", etc.)\n",
    "\n",
    "#   The LLM controls the flow by deciding whether to include tool_calls in its response!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO(human)\n",
    "# This is where you'll implement the agent's decision-making logic.\n",
    "# The agent node should:\n",
    "# 1. Take the current state and messages\n",
    "# 2. Call the LLM to decide what to do next\n",
    "# 3. Return updated state with the LLM's response\n",
    "#\n",
    "# Key considerations:\n",
    "# - Should the agent call a tool or provide a final answer?\n",
    "# - How do we pass conversation history to the LLM?\n",
    "# - What information from state should be included?\n",
    "\n",
    "def agent_node(state: BQAgentState) -> BQAgentState:\n",
    "    \"\"\"Main agent node that decides what to do next.\"\"\"\n",
    "    message = state[\"messages\"]\n",
    "    invocation = llm_with_tools.invoke(message) \n",
    "    return{\n",
    "        \"messages\" : [invocation]\n",
    "    } \n",
    "\n",
    "def should_continue(state: BQAgentState) -> str:\n",
    "    \"\"\"Decide whether to continue with tools or end.\"\"\"\n",
    "    messages = state[\"messages\"]\n",
    "    last_message = messages[-1]\n",
    "    \n",
    "    # If there are tool calls, continue to tools\n",
    "    if hasattr(last_message, 'tool_calls') and last_message.tool_calls:\n",
    "        return \"tools\"\n",
    "    # Otherwise, end\n",
    "    return \"end\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Build the Agent Graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Agent graph compiled successfully\n"
     ]
    }
   ],
   "source": [
    "# Create the state graph\n",
    "workflow = StateGraph(BQAgentState)\n",
    "\n",
    "# Add nodes\n",
    "workflow.add_node(\"agent\", agent_node)\n",
    "workflow.add_node(\"tools\", ToolNode(tools))\n",
    "\n",
    "# Set entry point\n",
    "workflow.set_entry_point(\"agent\")\n",
    "\n",
    "# Add conditional edges\n",
    "workflow.add_conditional_edges(\n",
    "    \"agent\",\n",
    "    should_continue,\n",
    "    {\n",
    "        \"tools\": \"tools\",\n",
    "        \"end\": END\n",
    "    }\n",
    ")\n",
    "\n",
    "# After tools, go back to agent\n",
    "workflow.add_edge(\"tools\", \"agent\")\n",
    "\n",
    "# Compile\n",
    "agent_app = workflow.compile()\n",
    "\n",
    "print(\"Agent graph compiled successfully\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test the agent with detailed inspection\n",
    "def run_agent(user_query: str, verbose: bool = True):\n",
    "    \"\"\"Run the agent with a user query.\"\"\"\n",
    "    initial_state = {\n",
    "        \"messages\": [HumanMessage(content=user_query)],\n",
    "        \"user_query\": user_query\n",
    "    }\n",
    "    \n",
    "    result = agent_app.invoke(initial_state)\n",
    "    \n",
    "    print(\"\\nAgent Response:\")\n",
    "    print(\"=\" * 80)\n",
    "    \n",
    "    for i, msg in enumerate(result[\"messages\"]):\n",
    "        if isinstance(msg, HumanMessage):\n",
    "            print(f\"\\n[{i}] User: {msg.content}\")\n",
    "            \n",
    "        elif isinstance(msg, AIMessage):\n",
    "            print(f\"\\n[{i}] Agent:\")\n",
    "            if msg.content:\n",
    "                print(f\"  Content: {msg.content}\")\n",
    "            if hasattr(msg, 'tool_calls') and msg.tool_calls:\n",
    "                print(f\"  Tool Calls:\")\n",
    "                for tool_call in msg.tool_calls:\n",
    "                    print(f\"    - {tool_call['name']}()\")\n",
    "                    if verbose:\n",
    "                        print(f\"      Args: {tool_call['args']}\")\n",
    "                        \n",
    "        elif isinstance(msg, ToolMessage):\n",
    "            print(f\"\\n[{i}] Tool Result ({msg.name}):\")\n",
    "            if verbose:\n",
    "                # Pretty print the result\n",
    "                result_preview = msg.content[:500] + \"...\" if len(msg.content) > 500 else msg.content\n",
    "                print(f\"  {result_preview}\")\n",
    "            else:\n",
    "                print(f\"  (length: {len(msg.content)} chars)\")\n",
    "    \n",
    "    print(\"\\n\" + \"=\" * 80)\n",
    "    \n",
    "    return result"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Example 1: List datasets - simple test\n",
    "print(\"TEST 1: Listing available datasets\")\n",
    "print(\"-\" * 80)\n",
    "result1 = run_agent(\"What datasets are available?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TEST 2: Running a query\n",
      "--------------------------------------------------------------------------------\n",
      "\n",
      "================================================================================\n",
      "EXECUTING SQL QUERY:\n",
      "--------------------------------------------------------------------------------\n",
      "SELECT name, SUM(number) AS total_babies FROM `bigquery-public-data.usa_names.usa_1910_current` WHERE year = 2020 GROUP BY name ORDER BY total_babies DESC LIMIT 5\n",
      "================================================================================\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/homebrew/Caskroom/miniconda/base/envs/platform/lib/python3.14/site-packages/google/cloud/bigquery/table.py:1994: UserWarning: BigQuery Storage module not found, fetch data with the REST endpoint instead.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✓ Query succeeded: 5 rows returned\n",
      "\n",
      "\n",
      "Agent Response:\n",
      "================================================================================\n",
      "\n",
      "[0] User: Get the top 5 most common names in the USA names dataset for babies born in 2020\n",
      "\n",
      "[1] Agent:\n",
      "  Tool Calls:\n",
      "    - execute_bigquery()\n",
      "      Args: {'sql_query': 'SELECT name, SUM(number) AS total_babies FROM `bigquery-public-data.usa_names.usa_1910_current` WHERE year = 2020 GROUP BY name ORDER BY total_babies DESC LIMIT 5'}\n",
      "\n",
      "[2] Tool Result (execute_bigquery):\n",
      "  {'success': True, 'row_count': 5, 'columns': ['name', 'total_babies'], 'sample_data': [{'name': 'Liam', 'total_babies': 19777}, {'name': 'Noah', 'total_babies': 18630}, {'name': 'Olivia', 'total_babies': 17641}], 'dtypes': {'name': 'object', 'total_babies': 'Int64'}}\n",
      "\n",
      "[3] Agent:\n",
      "  Content: The top 5 most common names in the USA for babies born in 2020 are:\n",
      "\n",
      "1. Liam (19777 babies)\n",
      "2. Noah (18630 babies)\n",
      "3. Olivia (17641 babies)\n",
      "4. Oliver (14601 babies)\n",
      "5. Elijah (13912 babies)\n",
      "\n",
      "================================================================================\n",
      "\n",
      "\n",
      "================================================================================\n",
      "EXTRACTING THE SQL QUERY FROM MESSAGES:\n",
      "================================================================================\n",
      "\n",
      "The LLM generated this SQL:\n",
      "--------------------------------------------------------------------------------\n",
      "SELECT name, SUM(number) AS total_babies FROM `bigquery-public-data.usa_names.usa_1910_current` WHERE year = 2020 GROUP BY name ORDER BY total_babies DESC LIMIT 5\n",
      "--------------------------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "# Example 2: Query data - this will show the SQL!\n",
    "print(\"TEST 2: Running a query\")\n",
    "print(\"-\" * 80)\n",
    "result2 = run_agent(\n",
    "    \"Get the top 5 most common names in the USA names dataset for babies born in 2020\"\n",
    ")\n",
    "\n",
    "# BONUS: Extract and display the SQL query from messages\n",
    "print(\"\\n\\n\" + \"=\"*80)\n",
    "print(\"EXTRACTING THE SQL QUERY FROM MESSAGES:\")\n",
    "print(\"=\"*80)\n",
    "for msg in result2[\"messages\"]:\n",
    "    if isinstance(msg, AIMessage) and hasattr(msg, 'tool_calls') and msg.tool_calls:\n",
    "        for tool_call in msg.tool_calls:\n",
    "            if tool_call['name'] == 'execute_bigquery':\n",
    "                sql = tool_call['args'].get('sql_query', '')\n",
    "                print(\"\\nThe LLM generated this SQL:\")\n",
    "                print(\"-\"*80)\n",
    "                print(sql)\n",
    "                print(\"-\"*80)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " <!-- The Flow of Information\n",
    "\n",
    "  Let me trace exactly what happens when you run run_agent(\"Get top 5 names in 2020\"):\n",
    "\n",
    "  Step 1: User Message Goes In\n",
    "\n",
    "  initial_state = {\n",
    "      \"messages\": [HumanMessage(content=\"Get top 5 names in 2020\")]\n",
    "  }\n",
    "\n",
    "  Step 2: Agent Node Processes It\n",
    "\n",
    "  Your agent_node function does this:\n",
    "  def agent_node(state: BQAgentState) -> BQAgentState:\n",
    "      messages = state[\"messages\"]  # Gets [HumanMessage(\"Get top 5...\")]\n",
    "      response = llm_with_tools.invoke(messages)  # Calls Gemini\n",
    "      return {\"messages\": [response]}  # Returns the LLM's response\n",
    "\n",
    "  Step 3: What the LLM Returns\n",
    "\n",
    "  The LLM doesn't return plain text. It returns an AIMessage object that looks like this:\n",
    "\n",
    "  AIMessage(\n",
    "      content=\"\",  # Empty because it wants to call a tool first\n",
    "      tool_calls=[\n",
    "          {\n",
    "              'name': 'execute_bigquery',\n",
    "              'id': 'call_abc123',\n",
    "              'args': {\n",
    "                  'sql_query': 'SELECT name, SUM(number) as total FROM ...'\n",
    "              }\n",
    "          }\n",
    "      ]\n",
    "  )\n",
    "\n",
    "  Key insight: The SQL query is inside tool_calls[0]['args']['sql_query']!\n",
    "\n",
    "  Step 4: The Router Checks\n",
    "\n",
    "  def should_continue(state: BQAgentState) -> str:\n",
    "      last_message = messages[-1]\n",
    "      if hasattr(last_message, 'tool_calls') and last_message.tool_calls:\n",
    "          return \"tools\"  # ← Goes here because tool_calls exists!\n",
    "\n",
    "  Step 5: ToolNode Executes\n",
    "\n",
    "  The ToolNode does this automatically:\n",
    "  1. Reads the tool_calls from the AIMessage\n",
    "  2. Finds the function named execute_bigquery\n",
    "  3. Calls it: execute_bigquery(sql_query='SELECT ...')\n",
    "  4. Returns a ToolMessage with the result\n",
    "\n",
    "  Step 6: My Two Methods to Show You the SQL\n",
    "\n",
    "  Method 1: Print inside the tool\n",
    "  @tool\n",
    "  def execute_bigquery(sql_query: str) -> str:\n",
    "      print(\"EXECUTING SQL QUERY:\")\n",
    "      print(sql_query)  # ← Prints when the function runs!\n",
    "      # ... rest of code\n",
    "\n",
    "  This prints the SQL while the tool is executing.\n",
    "\n",
    "  Method 2: Extract from messages afterwards\n",
    "  for msg in result2[\"messages\"]:\n",
    "      if isinstance(msg, AIMessage) and msg.tool_calls:\n",
    "          for tool_call in msg.tool_calls:\n",
    "              if tool_call['name'] == 'execute_bigquery':\n",
    "                  sql = tool_call['args']['sql_query']  # ← Extract it!\n",
    "                  print(sql)\n",
    "\n",
    "  This reads the SQL from the message history after everything is done.\n",
    "\n",
    "  Visual Diagram\n",
    "\n",
    "  User Query\n",
    "      ↓\n",
    "  agent_node → LLM → AIMessage(tool_calls=[{name: 'execute_bigquery', args: {sql_query: 'SELECT...'}}])\n",
    "      ↓\n",
    "  should_continue → sees tool_calls → routes to \"tools\"\n",
    "      ↓\n",
    "  ToolNode → extracts args → execute_bigquery(sql_query='SELECT...')\n",
    "      ↓                              ↓\n",
    "      ↓                         print(sql_query) ← Method 1: You see it here!\n",
    "      ↓\n",
    "  ToolMessage(result) → back to agent_node → LLM sees result → final answer\n",
    "      ↓\n",
    "  result[\"messages\"] ← Contains full history\n",
    "      ↓\n",
    "  Extract tool_calls['args']['sql_query'] ← Method 2: You see it here!\n",
    "\n",
    "  Why This Is Powerful\n",
    "\n",
    "  Everything is stored in messages! The message list is like a complete audit log:\n",
    "\n",
    "  result[\"messages\"] = [\n",
    "      HumanMessage(\"Get top 5...\"),           # [0] Your question\n",
    "      AIMessage(tool_calls=[...]),            # [1] LLM decides to call tool\n",
    "      ToolMessage(content=\"...\"),             # [2] Tool execution result\n",
    "      AIMessage(content=\"The top 5 are...\")   # [3] LLM's final answer\n",
    "  ]\n",
    "\n",
    "  You can inspect ANY part of this afterwards. The SQL is in messages[1].tool_calls[0]['args']['sql_query'].\n",
    "\n",
    "  ★ Insight ─────────────────────────────────────\n",
    "  Messages Are the Source of Truth: LangGraph's message-based architecture means every decision, every tool call, and every\n",
    "  result is explicitly stored. This is fundamentally different from traditional function calls where intermediate steps are\n",
    "  hidden. You can:\n",
    "  - Debug by inspecting message history\n",
    "  - Implement retry logic by modifying messages\n",
    "  - Build human-in-the-loop by pausing and editing messages\n",
    "  - Create branching logic based on message content\n",
    "  - Log everything for observability\n",
    "\n",
    "  The \"magic\" is just structured data passing through a graph! -->"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Agent Response:\n",
      "================================================================================\n",
      "\n",
      "[0] User: What datasets are available?\n",
      "\n",
      "[1] Agent:\n",
      "  Tool Calls:\n",
      "    - list_available_datasets()\n",
      "      Args: {}\n",
      "\n",
      "[2] Tool Result (list_available_datasets):\n",
      "  \n",
      "    Available public BigQuery datasets:\n",
      "\n",
      "    1. bigquery-public-data.usa_names.usa_1910_current\n",
      "       - US baby names from 1910 to present\n",
      "       - Columns: state, gender, year, name, number\n",
      "\n",
      "    2. bigquery-public-data.google_analytics_sample.ga_sessions_*\n",
      "       - Google Analytics session data\n",
      "       - Date range: 20160801 - 20170801\n",
      "\n",
      "    3. bigquery-public-data.chicago_crime.crime\n",
      "       - Chicago crime data\n",
      "       - Columns: date, primary_type, description, location_description, arrest, et...\n",
      "\n",
      "[3] Agent:\n",
      "  Content: The following public BigQuery datasets are available:\n",
      "\n",
      "1.  **bigquery-public-data.usa_names.usa_1910_current**\n",
      "    *   US baby names from 1910 to present\n",
      "    *   Columns: state, gender, year, name, number\n",
      "\n",
      "2.  **bigquery-public-data.google_analytics_sample.ga_sessions_\\***\n",
      "    *   Google Analytics session data\n",
      "    *   Date range: 20160801 - 20170801\n",
      "\n",
      "3.  **bigquery-public-data.chicago_crime.crime**\n",
      "    *   Chicago crime data\n",
      "    *   Columns: date, primary_type, description, location_description, arrest, etc.\n",
      "\n",
      "4.  **bigquery-public-data.samples.shakespeare**\n",
      "    *   Shakespeare's works\n",
      "    *   Columns: word, word_count, corpus, corpus_date\n",
      "\n",
      "================================================================================\n"
     ]
    }
   ],
   "source": [
    "# Example 1: List datasets\n",
    "result1 = run_agent(\"What datasets are available?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "================================================================================\n",
      "EXECUTING SQL QUERY:\n",
      "--------------------------------------------------------------------------------\n",
      "SELECT name, SUM(number) AS total_babies FROM `bigquery-public-data.usa_names.usa_1910_current` WHERE year = 2020 GROUP BY name ORDER BY total_babies DESC LIMIT 5\n",
      "================================================================================\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/homebrew/Caskroom/miniconda/base/envs/platform/lib/python3.14/site-packages/google/cloud/bigquery/table.py:1994: UserWarning: BigQuery Storage module not found, fetch data with the REST endpoint instead.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✓ Query succeeded: 5 rows returned\n",
      "\n",
      "\n",
      "Agent Response:\n",
      "================================================================================\n",
      "\n",
      "[0] User: Get the top 5 most common names in the USA names dataset for babies born in 2020\n",
      "\n",
      "[1] Agent:\n",
      "  Tool Calls:\n",
      "    - list_available_datasets()\n",
      "      Args: {}\n",
      "\n",
      "[2] Tool Result (list_available_datasets):\n",
      "  \n",
      "    Available public BigQuery datasets:\n",
      "\n",
      "    1. bigquery-public-data.usa_names.usa_1910_current\n",
      "       - US baby names from 1910 to present\n",
      "       - Columns: state, gender, year, name, number\n",
      "\n",
      "    2. bigquery-public-data.google_analytics_sample.ga_sessions_*\n",
      "       - Google Analytics session data\n",
      "       - Date range: 20160801 - 20170801\n",
      "\n",
      "    3. bigquery-public-data.chicago_crime.crime\n",
      "       - Chicago crime data\n",
      "       - Columns: date, primary_type, description, location_description, arrest, et...\n",
      "\n",
      "[3] Agent:\n",
      "  Tool Calls:\n",
      "    - execute_bigquery()\n",
      "      Args: {'sql_query': 'SELECT name, SUM(number) AS total_babies FROM `bigquery-public-data.usa_names.usa_1910_current` WHERE year = 2020 GROUP BY name ORDER BY total_babies DESC LIMIT 5'}\n",
      "\n",
      "[4] Tool Result (execute_bigquery):\n",
      "  {'success': True, 'row_count': 5, 'columns': ['name', 'total_babies'], 'sample_data': [{'name': 'Liam', 'total_babies': 19777}, {'name': 'Noah', 'total_babies': 18630}, {'name': 'Olivia', 'total_babies': 17641}], 'dtypes': {'name': 'object', 'total_babies': 'Int64'}}\n",
      "\n",
      "[5] Agent:\n",
      "  Content: [{'type': 'text', 'text': 'The top 5 most common names for babies born in 2020 are:\\n\\n1.  Liam (19777 babies)\\n2.  Noah (18630 babies)\\n3.  Olivia (17641 babies)\\n\\nThe query returned 5 results, but only the top 3 are available in the sample data.', 'thought_signature': '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'}]\n",
      "\n",
      "================================================================================\n"
     ]
    }
   ],
   "source": [
    "# Example 2: Query data\n",
    "result2 = run_agent(\n",
    "    \"Get the top 5 most common names in the USA names dataset for babies born in 2020\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 5: Adding Data Analysis and Visualisation\n",
    "\n",
    "Now let's extend our agent to analyse query results and create visualisations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Enhanced state with visualisation tracking\n",
    "class EnhancedBQAgentState(TypedDict):\n",
    "    messages: Annotated[Sequence[BaseMessage], operator.add]\n",
    "    query_result_df: object  # Store actual DataFrame\n",
    "    analysis: str\n",
    "    visualisation_config: dict\n",
    "    user_query: str"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO(human)\n",
    "# Implement a function to automatically select the best visualisation type.\n",
    "# This function should:\n",
    "# 1. Analyse the DataFrame (number of columns, data types, row count)\n",
    "# 2. Determine if it's time-series, categorical, numerical, etc.\n",
    "# 3. Return a recommended visualisation type and configuration\n",
    "#\n",
    "# Consider these visualisation types:\n",
    "# - bar chart: for categorical comparisons\n",
    "# - line chart: for time-series data\n",
    "# - scatter plot: for correlation between two numerical variables\n",
    "# - histogram: for distribution of single numerical variable\n",
    "# - pie chart: for part-to-whole relationships (use sparingly)\n",
    "\n",
    "def select_visualisation_type(df: pd.DataFrame, user_query: str) -> dict:\n",
    "    \"\"\"Analyse DataFrame and select appropriate visualisation.\n",
    "    \n",
    "    Args:\n",
    "        df: The DataFrame to visualise\n",
    "        user_query: The original user query for context\n",
    "        \n",
    "    Returns:\n",
    "        Dictionary with visualisation configuration\n",
    "    \"\"\"\n",
    "    \n",
    "    # Step 1: Gather information about the DataFrame\n",
    "    num_columns = len(df.columns)\n",
    "    column_names = df.columns.tolist()\n",
    "    dtypes = df.dtypes.to_dict()\n",
    "\n",
    "    # Step 2: Check for time-series indicators\n",
    "    time_columns = [col for col in column_names if col in ['year', 'date', 'time', 'month']]\n",
    "\n",
    "    # Step 3: Identify numerical vs categorical columns\n",
    "    numerical_cols = [col for col, dtype in dtypes.items() if dtype in ['int64', 'float64']]\n",
    "    categorical_cols = [col for col, dtype in dtypes.items() if dtype == 'object']\n",
    "\n",
    "      # Step 4: Decision logic - YOU IMPLEMENT THIS!\n",
    "      # Questions to answer:\n",
    "      # - If there's a 'year' column + numerical column → line chart?\n",
    "      # - If there's only categorical + numerical → bar chart?\n",
    "      # - If there are 2 numerical columns → scatter plot?\n",
    "\n",
    "    # TODO: Your logic here!\n",
    "\n",
    "    return config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_visualisation(df: pd.DataFrame, config: dict):\n",
    "    \"\"\"Create a visualisation based on the configuration.\"\"\"\n",
    "    viz_type = config.get('type', 'bar')\n",
    "    \n",
    "    if viz_type == 'bar':\n",
    "        fig = px.bar(\n",
    "            df,\n",
    "            x=config.get('x'),\n",
    "            y=config.get('y'),\n",
    "            title=config.get('title', 'Bar Chart'),\n",
    "            color=config.get('color')\n",
    "        )\n",
    "    elif viz_type == 'line':\n",
    "        fig = px.line(\n",
    "            df,\n",
    "            x=config.get('x'),\n",
    "            y=config.get('y'),\n",
    "            title=config.get('title', 'Line Chart'),\n",
    "            color=config.get('color')\n",
    "        )\n",
    "    elif viz_type == 'scatter':\n",
    "        fig = px.scatter(\n",
    "            df,\n",
    "            x=config.get('x'),\n",
    "            y=config.get('y'),\n",
    "            title=config.get('title', 'Scatter Plot'),\n",
    "            color=config.get('color'),\n",
    "            size=config.get('size')\n",
    "        )\n",
    "    elif viz_type == 'histogram':\n",
    "        fig = px.histogram(\n",
    "            df,\n",
    "            x=config.get('x'),\n",
    "            title=config.get('title', 'Histogram')\n",
    "        )\n",
    "    else:\n",
    "        # Default to bar chart\n",
    "        fig = px.bar(df, title='Data Visualisation')\n",
    "    \n",
    "    fig.update_layout(\n",
    "        template='plotly_white',\n",
    "        height=500,\n",
    "        showlegend=True\n",
    "    )\n",
    "    \n",
    "    return fig"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 6: Putting It All Together\n",
    "\n",
    "Let's create a complete workflow that queries, analyses, and visualises data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def complete_bq_workflow(user_query: str):\n",
    "    \"\"\"Complete workflow: query -> analyse -> visualise.\"\"\"\n",
    "    \n",
    "    print(f\"Processing: {user_query}\")\n",
    "    print(\"=\"*80)\n",
    "    \n",
    "    # Step 1: Run agent to get query results\n",
    "    print(\"\\nStep 1: Running agent to execute query...\")\n",
    "    result = run_agent(user_query)\n",
    "    \n",
    "    # Extract query result if available\n",
    "    # This is a simplified version - you'd need to enhance the agent\n",
    "    # to properly store DataFrame in state\n",
    "    \n",
    "    # For demonstration, let's run a sample query directly\n",
    "    sample_query = \"\"\"\n",
    "    SELECT \n",
    "        year,\n",
    "        name,\n",
    "        SUM(number) as total_births\n",
    "    FROM `bigquery-public-data.usa_names.usa_1910_current`\n",
    "    WHERE name IN ('Emma', 'Olivia', 'Liam', 'Noah')\n",
    "    AND year >= 2010\n",
    "    GROUP BY year, name\n",
    "    ORDER BY year, total_births DESC\n",
    "    \"\"\"\n",
    "    \n",
    "    print(\"\\nStep 2: Fetching data...\")\n",
    "    df = bq_client.query(sample_query).to_dataframe()\n",
    "    print(f\"Retrieved {len(df)} rows\")\n",
    "    print(df.head())\n",
    "    \n",
    "    # Step 2: Analyse the data\n",
    "    print(\"\\nStep 3: Analysing data...\")\n",
    "    analysis = f\"\"\"\n",
    "    Data Summary:\n",
    "    - Total rows: {len(df)}\n",
    "    - Columns: {', '.join(df.columns)}\n",
    "    - Year range: {df['year'].min()} to {df['year'].max()}\n",
    "    - Names analysed: {', '.join(df['name'].unique())}\n",
    "    \"\"\"\n",
    "    print(analysis)\n",
    "    \n",
    "    # Step 3: Select and create visualisation\n",
    "    print(\"\\nStep 4: Creating visualisation...\")\n",
    "    viz_config = {\n",
    "        'type': 'line',\n",
    "        'x': 'year',\n",
    "        'y': 'total_births',\n",
    "        'color': 'name',\n",
    "        'title': 'Name Popularity Trends (2010-Present)'\n",
    "    }\n",
    "    \n",
    "    fig = create_visualisation(df, viz_config)\n",
    "    fig.show()\n",
    "    \n",
    "    print(\"\\n\" + \"=\"*80)\n",
    "    print(\"Workflow complete!\")\n",
    "    \n",
    "    return df, analysis, fig"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run the complete workflow\n",
    "df, analysis, fig = complete_bq_workflow(\n",
    "    \"Show me the popularity trends for names Emma, Olivia, Liam, and Noah since 2010\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 7: Exercises and Challenges\n",
    "\n",
    "Now it's your turn to enhance the agent! Try these challenges:\n",
    "\n",
    "### Challenge 1: Implement the agent_node function\n",
    "Go back to the `agent_node` function and implement the logic to:\n",
    "- Call the LLM with current state\n",
    "- Handle tool calls appropriately\n",
    "- Return updated state\n",
    "\n",
    "### Challenge 2: Implement visualisation selection\n",
    "Complete the `select_visualisation_type` function to automatically choose the best chart type based on data characteristics.\n",
    "\n",
    "### Challenge 3: Add more tools\n",
    "Create additional tools:\n",
    "- `summarise_data`: Generate statistical summary of query results\n",
    "- `compare_queries`: Run multiple queries and compare results\n",
    "- `export_results`: Save results to different formats (CSV, JSON, etc.)\n",
    "\n",
    "### Challenge 4: Add conversation memory\n",
    "Enhance the agent to remember previous queries and allow follow-up questions like:\n",
    "- \"Show me the same data but for California only\"\n",
    "- \"Now create a bar chart instead\"\n",
    "\n",
    "### Challenge 5: Error handling and validation\n",
    "Add robust error handling:\n",
    "- Validate SQL queries before execution\n",
    "- Handle empty result sets gracefully\n",
    "- Provide helpful error messages"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Additional Resources\n",
    "\n",
    "- [LangGraph Documentation](https://langchain-ai.github.io/langgraph/)\n",
    "- [BigQuery Public Datasets](https://cloud.google.com/bigquery/public-data)\n",
    "- [Plotly Documentation](https://plotly.com/python/)\n",
    "- [LangChain Tools](https://python.langchain.com/docs/modules/agents/tools/)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Summary\n",
    "\n",
    "Congratulations! You've learned:\n",
    "\n",
    "1. **LangGraph Fundamentals**: How to create state graphs with nodes and edges\n",
    "2. **Tool Integration**: How to bind tools to LLMs and create tool nodes\n",
    "3. **Agent Orchestration**: How to build conditional workflows that make decisions\n",
    "4. **BigQuery Integration**: How to query and process data from BQ\n",
    "5. **Data Visualisation**: How to automatically select and create appropriate visualisations\n",
    "\n",
    "The key insight is that LangGraph separates **what** (state) from **how** (nodes) and **when** (edges), making complex agent workflows manageable and debuggable."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "platform",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.14.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
